# ğŸ” Biometric Gate Access  
**Secure, convenient, and automated access control with facial biometrics**  

---

## ğŸŒ Context & Motivation  

In todayâ€™s world, **convenience without compromising security** has become essential.  
Biometrics provide an **ideal and efficient solution**, combining **automation, safety, and user comfort**.  

â¡ï¸ This led us to design an **Android application** capable of:  
- ğŸšª Opening/closing gates  
- ğŸ”‘ Locking/unlocking doors  

â€¦all performed **rapidly through facial recognition**, offering a **secure, user-friendly, and automated access system**.  

<div align="center">
  <img src="images_BS/immagine6.jpg" width="400">
</div>

---

## ğŸ—ï¸ System Architecture  

The application relies on **three key modules**, executed on a dedicated server:  

### 1ï¸âƒ£ Face Detection ğŸ‘€  
- Detects the presence of a face in the images captured by the Android deviceâ€™s camera.  
- Uses **MTCNN** (from *FaceNet-PyTorch*) for reliable and efficient detection.  

### 2ï¸âƒ£ Liveness Detection ğŸ›¡ï¸  
- An **anti-spoofing module** ensuring the detected face belongs to a **live person**.  
- Prevents:  
  - ğŸ–¨ï¸ **Print Attacks** â†’ attempts using printed photos  
  - ğŸ“½ï¸ **Replay Attacks** â†’ attempts using recorded videos of genuine users  
- Implemented with **PyTorch**, using **MobileNet_v2** (with and without *Local Binary Pattern* preprocessing) for robust performance.  

### 3ï¸âƒ£ Face Recognition ğŸ¤  
- Extracts facial embeddings via **deep learning**.  
- Uses **FaceNet-PyTorch** (Inception Resnet V1, pre-trained on *VGGFace2* & *CASIA-WebFace*).  
- Performs **verification** (1:1 comparison) to check if the declared identity matches the stored template.  
- âœ… Accept â†’ if embeddings match  
- âŒ Reject â†’ otherwise  

---

## ğŸ“¡ Hardware Integration  

The **Android application communicates with a Raspberry Pi** through an **HTTP Flask server**.  

- âš™ï¸ **Raspberry Pi GPIO Pins** connect to a **motor driver (L298N)**.  
- The **L298N driver** controls a **linear actuator**, responsible for:  
  - ğŸ¡ Pressing the intercom button to open/close a gate  
  - ğŸšª Engaging or disengaging door latches  

This setup bridges **biometric authentication** with **physical control mechanisms**.  

<div align="center">
  <img src="images_BS/Immagine2.jpg" width="500">
</div>

---

## ğŸ”‘ Enrollment & Verification Policies  

The biometric pipeline consists of **two main phases**:  

### ğŸ“ Enrollment Phase  
- The system requires **three face images** from the user.  
- âœ… Only if all three images contain a valid face â†’ proceed to **feature extraction & template creation**.  
- âŒ Otherwise â†’ request the user to retake the images.  
- Templates are stored on the server and linked to the userâ€™s **Android ID** (unique device identifier).  

<div align="center">
  <img src="images_BS/Immagine3.png" width="500">
</div>

### ğŸ” Verification Phase  
- Similarly, the system requires **three face images** for verification.  
- Images undergo **preprocessing** (resizing & normalization).  
- âœ… Pipeline flow:  
  1. **Face Detection** â†’ if any image fails â†’ `reject`  
  2. **Liveness Detection** â†’ if any image is spoofed â†’ `reject`  
  3. **Face Recognition** â†’ compare extracted features against stored templates (linked to Android ID)  
     - If match â†’ `accept`  
     - Else â†’ `reject`
    
<div align="center">
  <img src="images_BS/Immagine4.png" width="500">
</div>

This **multi-step verification policy** ensures **accuracy, robustness, and resistance to spoofing attacks**.  

---

## âš™ï¸ Technologies Used  

- **Android App** ğŸ“± â†’ User interface & camera capture  
- **Server** ğŸ–¥ï¸ â†’ Manages face detection, liveness, and recognition  
- **Raspberry Pi + L298N** ğŸ”§ â†’ Physical actuation (gates & doors)  
- **Libraries & Frameworks**:  
  - [PyTorch](https://pytorch.org/) â†’ Training & evaluation of models  
  - [FaceNet-PyTorch](https://github.com/timesler/facenet-pytorch) â†’ Face recognition & detection (MTCNN, Inception Resnet V1)  
  - [MobileNet_v2](https://pytorch.org/vision/stable/models/generated/torchvision.models.mobilenet_v2.html) â†’ Liveness detection model  
  - [Local Binary Pattern (LBP)](https://en.wikipedia.org/wiki/Local_binary_patterns) â†’ Image preprocessing for robustness  

---

## ğŸ§  Machine Learning Approach  

- ğŸŸ£ **Deep Learning Models** used for all three biometric modules  
- âš¡ **GPU acceleration** with PyTorch for efficient tensor operations  
- ğŸ“Š Models evaluated **with and without preprocessing** (LBP) for liveness detection  
- ğŸ† Chosen architecture ensures:  
  - High accuracy âœ…  
  - Real-time processing â±ï¸  
  - Strong resistance against spoofing attempts ğŸ”’  

---

## ğŸ“‚ Dataset Preparation  

To properly evaluate and train the different modules of our biometric access system, we combined **public datasets** with a **manually created dataset**.  

### ğŸ‘€ Face Detection Dataset  
- **Positive class**: Images from  
  - ğŸ“· Labelled Faces in the Wild (LFW)  
  - ğŸ–¼ï¸ NUAA Photograph Imposter Database  
  - ğŸ¥ MSU-MFSD  

- **Negative class**: Manually collected confusing examples, such as:  
  - ğŸ¶ğŸ±ğŸ´ğŸ¦ğŸ˜ Animals (dogs, cats, horses, lions, elephants)  
  - âš½ğŸ Round or oval objects (balls, spheres)  

ğŸ‘‰ This design ensured the model faced **challenging scenarios**, simulating objects with **facial-like structures**.  

---

## ğŸ§  Face Detection Module  

We implemented **MTCNN (Multi-task Cascaded Convolutional Networks)** for face detection.  

- **Evaluation set**: 6000 manually prepared images  
- **Results**:  
  - âŒ False Positive Rate (FPR): **2.47%**  
  - ğŸ¯ Missed Face Rate (MFR): **0.00%**  

âœ… The **0.00% MFR** demonstrates that the model **never failed to detect a human face**.  
âš ï¸ False positives occurred mainly with **animals or spherical objects** deliberately included to confuse the model.  

---

## ğŸ›¡ï¸ Liveness Detection Module  

We trained **MobileNet_v2** (with a custom final layer for binary classification: *real vs. spoof*) using the **NUAA** and **MSU-MFSD** datasets.  

### âš™ï¸ Training Setup  
- ğŸ”„ **10 epochs**  
- ğŸ“¦ Batch size: **32**  
- ğŸ“‰ Learning rate: **0.0001**  
- ğŸ” Tested **with and without Local Binary Pattern (LBP) preprocessing**  

### âœ¨ Why LBP?  
- Emphasizes **texture details**  
- Highlights **printing defects** in photo attacks  
- Detects surface differences (e.g., light reflection, unnatural colors)  

### ğŸ§ª Experiments  
- âœ… Trained MobileNet with/without LBP on one dataset, evaluated on the other (**cross-dataset evaluation**)  
- âœ… Tested models on **unseen partitions** from the same dataset  
- ğŸ“ Metrics used:  
  - ğŸ”¹ APCER (Attack Presentation Classification Error Rate)  
  - ğŸ”¹ BPCER (Bona Fide Presentation Classification Error Rate)  
  - ğŸ”¹ ACER (Average Classification Error Rate)  
  - ğŸ”¹ Accuracy, Precision, Recall, F1-score  

### ğŸ“Š Findings  
- **High performance** when tested on the same dataset used for training  
- **Performance drop** on cross-dataset evaluation, due to differences in:  
  - ğŸŒ— Lighting conditions  
  - ğŸ‘¤ Subject diversity  
  - ğŸ“± Capture devices (smartphones, tablets, laptops)  
- **Best results**: Training on a **combined dataset** â†’ improved generalization, robust even **in real-time scenarios**  

---

## ğŸ§¾ Face Recognition Module  

For **face recognition**, we used **Labelled Faces in the Wild (LFW)** and performed a **verification single-template ALL-against-ALL evaluation**.  

### âš™ï¸ Experimental Setup  
- 8 experiments conducted  
- Compared:  
  - ğŸ“Š **CASIA-WebFace pre-trained model**  
  - ğŸ“Š **VGGFace2 pre-trained model**  
- Variable **S**: number of templates per subject  
- Metrics visualized through:  
  - FAR (False Acceptance Rate) vs. FRR (False Rejection Rate)  
  - ğŸ“ˆ **ROC curve**  
  - ğŸ“‰ **DET curve**  
  - Equal Error Rate (EER) point  

### ğŸ“Š Results  

#### VGGFace2  
- Outperformed CASIA-Webface across all values of **S**  
- **Best case (S=3)**:  
  - GAR (Genuine Acceptance Rate): **0.97**  
  - GRR (Genuine Rejection Rate): **0.97**  
  - âœ… Excellent recognition ability  
  - ROC Curve â†’ **AUC = 1.0** (near-perfect performance)  
  - DET Curve â†’ Low FAR and FRR, minimal errors  

#### CASIA-Webface  
- Performance **deteriorated with higher values of S**  
- Struggled with **intra-class variations**:  
  - Different poses  
  - Lighting changes  
  - Facial expressions  
- These limitations were more evident in **uncontrolled conditions** (like LFW dataset images).  

---

## Authors
- [@Pnlalessio](https://github.com/Pnlalessio)  
- [@JessicaFrabotta](https://github.com/JessicaFrabotta)

---
